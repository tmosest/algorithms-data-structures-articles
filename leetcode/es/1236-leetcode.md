-...
T√≠tulo: LeetCode 1236. Web Crawler -
descripci√≥n: Titular
Fecha: 2025-09-21
categor√≠as: []
autor: muses
tags: []
HideToc: verdadero
-...
# üöÄ Mastering Leetcode 1236 ‚Äì **Web Crawler* *
**Java ‚ãÖ Python ‚Üê Soluciones C++ + un completo "Good / Bad / Ugly" blog post* *

‚ñ† *‚ÄúSi quieres conseguir un trabajo de ingenier√≠a de software, necesitas crear los problemas cl√°sicos de entrevista. Leetcode 1236 (Web Crawler) es una mina de oro que prueba traversal gr√°fico, persiguiendo cadenas y manejando minuciosamente el borde.*

-...

Problema Recap

‚ñ† * Objetivo* ‚Äì Partiendo de `start Url`, gate every URL that lies under the *same hostname* (e.g. `http://example.org`) using the provided `HtmlParser`.
‚ñ† **Constraints**
* No hay rastreo duplicado (cada URL visitada s√≥lo una vez).
* Ignorar URLs que apuntan a un nombre de host diferente.
* Trate URLs con / sin un corte de seguimiento como distinto.
* Todas las URL utilizan el protocolo http` y no puertos personalizados.

‚ñ† **Output** ‚Äì Una lista de todas las URL accesibles (cualquier orden).

‚ñ† **Hora** ‚Äì O(V + E)
‚ñ† **Espacio** ‚Äì O(V)

-...

## üîß Solution Overview

El gr√°fico es impl√≠cito: cada URL es un nodo, y los bordes son los hiperv√≠nculos devueltos por `htmlParser.getUrls(url)`.
Un cl√°sico **Breadth‚ÄêFirst Search (BFS)** (o Depth‚ÄêFirst Search) es todo lo que necesitamos.

1. **Extraer el nombre de host** de `startUrl`.
`hostname = url[7: url.find('/', 7)] ' (la parte despu√©s de " http:// " y antes de la primera " despu√©s de ella).
2. **Queue** ‚Äì for BFS; **Stack** ‚Äì for DFS.
3. **Equipo visitado** ‚Äì para evitar revisitar URLs.
4. Mientras que la cola/estar no est√° vac√≠a:
* Pop a URL.
* Pregunta `htmlParser.getUrls(url)` para vecinos.
* Para cada vecino que comparte el nombre de host **y** no ha sido visitado, agr√©guelo al conjunto visitado y empuje hacia la cola/estar.
5. Devuelve el conjunto visitado como una lista.

-...

C√≥digo - Java

``java
importar java.util*;

Clase Soluci√≥n {
* Interfaz dada por la plataforma (no implementado) */
interfaz HtmlParser {
Lista de datos:
}

public List won(String) Url, HtmlParser htmlParser) {
String host = getHostname(startUrl);

Queue wonString conf√≠a q = nuevo ArrayDeque corresponde();
Establecer:String titulada visitado = nuevo HashSet correctamente();

q.offer(startUrl);
visitado.add(startUrl);

(!q.isEmpty()) {
Url de cuerda = q.poll();
for (String nxt : htmlParser.getUrls(url) {
si (nxt.startsWith(host) " Visit.add(nxt)) {}
q.offer(nxt);
}
}
}
devolver nuevo ArrayList garantizado(visited);
}

privada String getHostname(String url) {
int idx = url.indexOf('/', 7); // skip "http://"
retorno idx == -1 ? url : url.substring(0, idx);
}
}
`` `

-...

C√≥digo Python

``python
de las colecciones importa
de la importaci√≥n Lista

# La plataforma suministra esta interfaz ‚Äì no la implementa
clase HtmlParser:
def getUrls(self, url: str) - Propiedad Lista[str]:
...

Soluci√≥n de clase:
def gate(self, startUrl: str, htmlParser: HtmlParser) - edad List[str]:
host = self._hostname(startUrl)

q = deque([startUrl])
visitados = {start Url.

mientras q:
url = q.popleft()
para nxt en htmlParser.getUrls(url):
si nxt.startswith(host) y nxt no en visitado:
visitado.add(nxt)
q.append(nxt)

lista de retorno(visitado)

@staticmethod
def _hostname(url: str) - t√≠tulo str:
idx = url.find('/', 7) # skip "http://"
retorno url si idx == -1 url[:idx]
`` `

-...

C√≥digo C++

``cpp
#include ‚ñ†string
Incluido el t√≠tulo
#include >
#include ‚ñ†unordered_set
usando std namespace;

// La plataforma suministra esta interfaz ‚Äì no implementa
clase HtmlParser
public:
vector virtual identificador confianza getUrls(const string paciente url) = 0;
};

Clase Soluci√≥n {
public:
vectoriales conectados Url, HtmlParser borde htmlParser) {
string host = getHostname(startUrl);

queue hac√≠a referencia q;
unordered_set buscadostring confianza visitado;

q.push(startUrl);
visitado.insert(startUrl);

(!q.empty()) {
string url = q.front(); q.pop();
vector realizador inferior = htmlParser.getUrls(url);
para (continuar cadena nxt : neigh) {
si (nxt.compare(0, host.size(), host) == 0 "
visitado.insert(nxt).second) { // insertado con √©xito
q.push(nxt);
}
}
}
vector de retorno identificado(visited.begin(), visited.end());
}

privado:
cadena est√°tica getHostname(const string paciente url) {
size_t pos = url.find('/', 7); // skip "http://"
retorno pos == cuerda::npos ? url : url.substr(0, pos);
}
};
`` `

-...

## üìö El bien, el mal, y el ugly" ‚Äì Entrevista Insight

Silencio Silencio
Silencio------------Prince------
Silencio **La opci√≥n de traversal de Gr√°ficos** TEN BFS garantiza una profundidad m√≠nima; DFS es m√°s simple de escribir recursivamente TEN la recursi√≥n DFS puede soplar la pila para grandes webs TEN Ninguno ‚Äì ambos trabajo; elegir el que usted est√° c√≥modo explicando TEN
Silencio **Extractaci√≥n de nombres de pila** Silencio Simple `startswith` check saves time TEN Hard to get right on the first try (off-by‚Äêone, missing protocol) Silencio Olvidar manejar URLs sin un slash (e.g. `http://a.com` vs `http://a.com/`) conduce a respuestas incorrectas TENED
Silencio **Manejo de inicios visitados** Silencio `HashSet`/`unordered_set` previene O(n) lookups ‚Üê Necesita insertar *y* comprobar si la inserci√≥n tuvo √©xito ‚Üê Mis‚Äêusing `insert` vs `find` in C++ puede producir errores sutiles ANTE
Silencio **String matching** Silencio `startsWith(host)` is O(1) Silencio Usar `contains(host)` puede coincidir incorrectamente con `http://evil.com` no escapar caracteres especiales ni manejar `https://` conduce a falsos positivos tenci√≥n
Silencio **Profundidad de la recusi√≥n** Silencio La recidiva DFS es elegante. 104 ‚Üí accidente de tiempo de ejecuci√≥n
Silencio **Complejidad** Silencio O(V + E) ‚Äì √≥ptimo para entrevistar TENIDO Ninguno TENIDO Olv√≠date del filtro hostname ‚Üí O(V + E + X) donde X es el n√∫mero de enlaces cross-host TEN
Silencio **Problemas de emergencia** Silencios de trailing tratados como distintos (consulte expl√≠cita) Las URLs de la vida pueden contener params de consulta; todav√≠a el mismo nombre de host ‚Äì fino ¬¶ Urls` devolver la misma URL repetidamente ‚Äì todav√≠a seguro debido al conjunto visitado

### Take-away

*Siempre explica tus opciones de dise√±o. *
D√≠gale al entrevistador por qu√© est√° usando BFS, c√≥mo est√° garantizando no duplicados, y c√≥mo est√° extrayendo el nombre de host de forma segura.
Si usted tambi√©n puede se√±alar las trampas (por ejemplo, la parte ‚Äúmuy‚Äù del corte de cuerdas) demostrar√° la madurez.

-...

## üîë C√≥mo usar esto en una entrevista de trabajo

1. **Mostrar el esqueleto** ‚Äì empezar con la interfaz de plataforma y la clase 'Solution'.
2. **A trav√©s de la extracci√≥n de nombres de host** ‚Äì explica por qu√© el √≠ndice comienza a las 7 (`"http://').
3. **Discuten las estructuras de datos** ‚Äì por qu√© un 'queue' sobre una pila (si elige BFS).
4. ** Complejidad estatal** ‚Äì enfatizar el comportamiento O(V + E).
5. **Las dificultades de la menci√≥n** ‚Äì las barras que siguen, las URL duplicadas, los l√≠mites de la recursi√≥n.

‚ñ† **Tip**: Si el entrevistador pide una versi√≥n DFS, cambie la cola para una pila o un ayudante recursivo. La l√≥gica central sigue siendo la misma.

-...

## üéØ SEO‚ÄêOptimized Blog Post

‚ñ† *T√≠tulo*
‚ñ† *‚ÄúMastering Leetcode 1236: Web Crawler ‚Äì The Good, The Bad, and The Ugly‚Äù*

‚ñ† **Meta‚ÄêKeywords**:
" Leetcode 1236 Web Crawler " , `Java BFS Web Crawler ' , `Python DFS Web Crawler`, `C++ Leetcode solutions " , `entrevista de ingenier√≠a de software ' , `consejos de entrevista de codificaci√≥n ' , `problemas de entrevista de trabajo `

Art√≠culo

‚ñ† **Introducci√≥n**
‚ñ† El problema Web Crawler es una gema oculta en el cubo de Leetcode ‚ÄúGraph‚Äù.
‚ñ† Te obliga a cambiar el traversal gr√°fico con manipulaci√≥n de cuerdas ‚Äì una entrevista cl√°sica combo.

‚ñ† **Lo que lo hace grande para su resumen* *
* Demonstrates mastery of BFS/DFS.
* Destaca la atenci√≥n al detalle (extracci√≥n de nombres anfitriones, manipulaci√≥n duplicada).
* Muestra la capacidad de escribir c√≥digo limpio y reutilizable en varios idiomas.

‚ñ† *Code Snippets*
‚Ä¢ Java (BFS) ‚Äì ver secci√≥n arriba
‚Ä¢ Python (BFS) ‚Äì ver secci√≥n arriba
(BFS) ‚Äì ver la secci√≥n anterior

‚ñ† ** An√°lisis de la complejidad**
* **Hora**: Cada URL se procesa una vez; cada borde (hiperenlace) examinado una vez ‚Üí O(V + E).
* **Espacio**: La cola/stack tiene en la mayor√≠a de las direcciones URL accesibles ‚Üí O(V).

‚ñ† **Entrevista com√∫n Pitfalls* *
‚ñ† 1. ** Hostname parsing** ‚Äì principiantes a menudo olvidan el offset de 7 para `"http://" o URL de mal manejo sin un seguimiento `/`.
‚ñ† 2. ** Conjunto visitado** ‚Äì utilizando `visitado. contiene ` entonces `add` puede doble-procesar un nodo si no es cuidadoso.
‚ñ† 3. ** Profundidad de la recusi√≥n** ‚Äì una ingenua recidiva DFS puede alcanzar el l√≠mite de la pila en una cadena de enlace muy profunda.

‚ñ† **Pro-Tip**
‚ñ† Escribe un ayudante `getHostname()` primero. Pru√©balo en casos de borde:
* http://a.com ' (no slash)
* http://a.com/` (root)
* http://a.com/path`

‚ñ† #Wrap-Up #
‚ñ† Mastering Web Crawler le proporciona una plantilla robusta para *cualquier* problema de entrevistas gr√°ficas. Practica el patr√≥n BFS/DFS, ajusta la l√≥gica de uni√≥n de cadenas para diferentes dominios, y estar√°s listo para asar la pr√≥xima ronda de codificaci√≥n.

‚ñ† ** Call‚Äêto-Action**
‚ñ† ¬øQuieres ver m√°s minas de oro Leetcode? ¬°S√≠gueme en GitHub, LinkedIn y Medium para soluciones de entrevistas de tama√±o de mordedura que entrevistan tierras!

-...

## üìû Ready to Land Your Next Job?

Dejame una l√≠nea en Linked En si desea una inmersi√≥n m√°s profunda, una entrevista de mock o un plan de estudio personalizado.
* Vamos a convertir Leetcode 1236 en su historia de √©xito de entrevista! *

-..